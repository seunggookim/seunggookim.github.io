<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator><link href="https://seunggookim.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://seunggookim.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2026-02-24T15:03:43+00:00</updated><id>https://seunggookim.github.io/feed.xml</id><title type="html">blank</title><subtitle>Computational Affective Neuroscience of Music </subtitle><entry><title type="html">Surfing LEA üèÑ‚Äç‚ôÄÔ∏èüëß</title><link href="https://seunggookim.github.io/blog/2025/surf/" rel="alternate" type="text/html" title="Surfing LEA üèÑ‚Äç‚ôÄÔ∏èüëß"/><published>2025-03-23T00:00:00+00:00</published><updated>2025-03-23T00:00:00+00:00</updated><id>https://seunggookim.github.io/blog/2025/surf</id><content type="html" xml:base="https://seunggookim.github.io/blog/2025/surf/"><![CDATA[<p>First, surface-based analysis is cool because the cerebral cortex üß† looks like a 2-D Riemannian (differentiable) manifold, of which functional organization seems to be governed by geodesic proximity rather than Euclidean proximity at a mesoscale (a few centimeters or less). So, a surface-based analysis is attractive, also for linearized encoding analysis! üëß‚ù§Ô∏èüèÑ‚Äç‚ôÄÔ∏è</p> <p>However, there are some things that make surface-based analysis more difficult than volume-based analysis.</p> <h2 id="prerequisites">Prerequisites</h2> <p>Which information do we need to define a surface? And which information do we need to define a volume?</p> <h3 id="volume">Volume</h3> <p>A digital 3-D image (i.e., a volume) is a tensor (or an 3-D array). For example, say we have a 3-D image with 2 rows, 3 columns, and 2 pages like:</p> \[\mathbf{I} \in \mathbb{N}^{2 \times 3 \times 2} = \left[ \begin{array}{c} \begin{bmatrix} a &amp; b &amp; c \\ d &amp; e &amp; f \end{bmatrix}, \begin{bmatrix} g &amp; h &amp; i \\ j &amp; k &amp; l \end{bmatrix} \end{array} \right]\] <p>This image itself does not have any location information in it, but we organize them so that it preserves relative spatial information. That is, the value $b$ itself doesn‚Äôt say anything about its location $(1,2,1)$ but we know that $b$ is one column after $a$ and one page before $h$ from the arrangement of the 3-D array. Such relative information may be sufficient in many applications. But in neuroimaging, and medical imaging in general, it is very important to precisely know how the voxel $(1,2,1)$ corresponds to a real-world coordinate (i.e., is it $(1, 2, 1) \mathrm{mm}$ or $(10,-200,0.1) \mathrm{cm}$?). And this is defined by the orders and directions of axes, as well as the sampling spacing (or voxel dimensions).</p> <p>Why should we consider different orientations of axes? Because we are looking at a matrix as shown above, we may think it would be <strong>natural</strong> to map LEFT-to-RIGHT along the columns and UP-to-DOWN along the rows (i.e., ‚ÄúDown‚Äù for the first dimension; ‚ÄúRight‚Äù for the second dimension; can be written as ‚ÄúDR‚Äù). However, if we think about a Cartesian plane, we may think that the first coordinate (row) should increase along the LEFT-to-RIGHT direction an the second coordinate (column) should increase along the DOWN-to-UP direction (i.e., ‚ÄúRU‚Äù) There are different conventions for the orientations of axes, and all conventions are valid. Often, these are written as a three-character string, representing a direction that increases a coordinate of each dimension in Left, Right, Anterior, Posterior, Superior, Inferior. For example, LAS in radiology; RAS in neurology; RSA or RSP in 3D computer graphics. Of course, are we talking about the viewer‚Äôs left or the subject‚Äôs left? It all makes sense in one way.</p> <p>One simple yet inefficient way to solve this is to save a list of coordinates together with the value map like:</p> <table> <thead> <tr> <th>Voxel</th> <th>World (mm)</th> </tr> </thead> <tbody> <tr> <td>(1, 1, 1)</td> <td>(-0.5, -3, 0.5)</td> </tr> <tr> <td>(1, 2, 1)</td> <td>(-0.5, -2, 0.5)</td> </tr> <tr> <td>:</td> <td>:</td> </tr> </tbody> </table> <p>This list will grow as we have more voxels. A conventional anatomical image contains 4M+ voxels and a functional image has 300K+ voxels. Moreover, this pair of coordinates can be even larger than the scalar value we need to save. Not a very good ideaüòï.</p> <p>A lot more elegant and efficient way is to formulate this problem as an affine transformation (because it is!):</p> \[\begin{bmatrix} x_w \\ y_w \\ z_w \\ 1 \end{bmatrix} = \begin{bmatrix} a_{11} &amp; a_{12} &amp; a_{13} &amp; t_x \\ a_{21} &amp; a_{22} &amp; a_{23} &amp; t_y \\ a_{31} &amp; a_{32} &amp; a_{33} &amp; t_z \\ 0 &amp; 0 &amp; 0 &amp; 1 \end{bmatrix} \begin{bmatrix} x_v \\ y_v \\ z_v \\ 1 \end{bmatrix},\] <p>where $\begin{bmatrix}x_w &amp; y_w &amp; z_w\end{bmatrix}^\mathrm{T}$ denote a 3-D world coordinate, $\begin{bmatrix}x_v &amp; y_v &amp; z_v\end{bmatrix}^\mathrm{T}$ denotes a 3-D voxel coordinate, $(a_{ij})$ are rotation and scaling components, and $\begin{bmatrix}t_x &amp; t_y &amp; t_z\end{bmatrix}^\mathrm{T}$ are translation components.</p> <p>In this way, we only need to save 12 elements in the transformation matrix (the 4 in the last row are always the same), and calculate the world coordinate of a certain voxel on the fly when asked by computing a small matrix-vector multiplication. The same 12 numbers will generate an accurate world coordinate for every voxel in the volume! (We never have to store a list of coordinate mapping for 4M+ voxels!üòù)</p> <p>So, for a volume data, we need to know the voxel-to-world transformation matrix. The world-to-voxel transformation matrix can be easily found by inverting the 4-by-4 matrix (takes about 4.8 msec), which can be costly if you also repeat this for 4M+ times (like 5+ hours). So, it makes more sense to just store another set of 12 numbers. In neuroimaging community, a standard format called NIfTI (<a href="https://nifti.nimh.nih.gov/">Neuroimaging Informatics Technology Initiative</a>) has been used since 2004. Only after many years, MALTAB included read/write functions in its Image Processing Toolbox since R2017b.</p> <ul id="surf2" class="tab" data-tab="4a8bae71-50af-4e30-802f-a1488eae6f89" data-name="surf2"> <li class="active" id="surf2-matlab"> <a href="#">matlab </a> </li> </ul> <ul class="tab-content" id="4a8bae71-50af-4e30-802f-a1488eae6f89" data-name="surf2"> <li class="active"> <div class="language-matlab highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;&gt;</span> <span class="n">Info</span> <span class="o">=</span> <span class="n">niftiinfo</span><span class="p">(</span><span class="s1">'MNI152_T1_2mm.nii.gz'</span><span class="p">)</span>

<span class="n">Info</span> <span class="o">=</span> 

  <span class="nb">struct</span> <span class="n">with</span> <span class="n">fields</span><span class="p">:</span>

                 <span class="n">Filename</span><span class="p">:</span> <span class="s1">'/Volumes/APFS-2TB/extendedhome/fsl/data/standard/MNI152_T1_2mm.nii.gz'</span>
              <span class="n">Filemoddate</span><span class="p">:</span> <span class="s1">'22-Aug-2022 16:51:53'</span>
                 <span class="n">Filesize</span><span class="p">:</span> <span class="mi">1406977</span>
                  <span class="n">Version</span><span class="p">:</span> <span class="s1">'NIfTI1'</span>
              <span class="n">Description</span><span class="p">:</span> <span class="s1">'FSL5.0'</span>
                <span class="n">ImageSize</span><span class="p">:</span> <span class="p">[</span><span class="mi">91</span> <span class="mi">109</span> <span class="mi">91</span><span class="p">]</span>
          <span class="n">PixelDimensions</span><span class="p">:</span> <span class="p">[</span><span class="mi">2</span> <span class="mi">2</span> <span class="mi">2</span><span class="p">]</span>
                 <span class="n">Datatype</span><span class="p">:</span> <span class="s1">'int16'</span>
             <span class="n">BitsPerPixel</span><span class="p">:</span> <span class="mi">16</span>
               <span class="n">SpaceUnits</span><span class="p">:</span> <span class="s1">'Millimeter'</span>
                <span class="n">TimeUnits</span><span class="p">:</span> <span class="s1">'Second'</span>
           <span class="n">AdditiveOffset</span><span class="p">:</span> <span class="mi">0</span>
    <span class="n">MultiplicativeScaling</span><span class="p">:</span> <span class="mi">1</span>
               <span class="n">TimeOffset</span><span class="p">:</span> <span class="mi">0</span>
                <span class="n">SliceCode</span><span class="p">:</span> <span class="s1">'Unknown'</span>
       <span class="n">FrequencyDimension</span><span class="p">:</span> <span class="mi">0</span>
           <span class="n">PhaseDimension</span><span class="p">:</span> <span class="mi">0</span>
         <span class="n">SpatialDimension</span><span class="p">:</span> <span class="mi">0</span>
    <span class="n">DisplayIntensityRange</span><span class="p">:</span> <span class="p">[</span><span class="mi">3000</span> <span class="mi">8000</span><span class="p">]</span>
            <span class="n">TransformName</span><span class="p">:</span> <span class="s1">'Sform'</span>
                <span class="n">Transform</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="err">√ó</span><span class="mi">1</span> <span class="n">affine3d</span><span class="p">]</span>
                  <span class="n">Qfactor</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span>
                      <span class="n">raw</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="err">√ó</span><span class="mi">1</span> <span class="nb">struct</span><span class="p">]</span>

<span class="o">&gt;&gt;</span> <span class="n">Info</span><span class="o">.</span><span class="n">Transform</span><span class="o">.</span><span class="n">T</span>

<span class="nb">ans</span> <span class="o">=</span>

    <span class="o">-</span><span class="mi">2</span>     <span class="mi">0</span>     <span class="mi">0</span>     <span class="mi">0</span>
     <span class="mi">0</span>     <span class="mi">2</span>     <span class="mi">0</span>     <span class="mi">0</span>
     <span class="mi">0</span>     <span class="mi">0</span>     <span class="mi">2</span>     <span class="mi">0</span>
    <span class="mi">90</span>  <span class="o">-</span><span class="mi">126</span>   <span class="o">-</span><span class="mi">72</span>     <span class="mi">1</span>
</code></pre></div></div> </li> </ul> <p>Now you can see the matrix is transposed!üôÉ But don‚Äôt worry, it just swaps the order:</p> \[\begin{split} \mathbf{w}^{\mathrm{T}} &amp;= \left( \mathbf{T}\mathbf{v} \right)^{\mathrm{T}} \\ \mathbf{w}^{\mathrm{T}} &amp;= \mathbf{v}^{\mathrm{T}}\mathbf{T}^{\mathrm{T}} \end{split}\] <p>You can also check the original header format stores three 4-dimensional row vectors:</p> <div class="language-matlab highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;&gt;</span> <span class="n">Info</span><span class="o">.</span><span class="n">raw</span>
            <span class="p">:</span>
            <span class="n">srow_x</span><span class="p">:</span> <span class="p">[</span><span class="o">-</span><span class="mi">2</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">90</span><span class="p">]</span>
            <span class="n">srow_y</span><span class="p">:</span> <span class="p">[</span><span class="mi">0</span> <span class="mi">2</span> <span class="mi">0</span> <span class="o">-</span><span class="mi">126</span><span class="p">]</span>
            <span class="n">srow_z</span><span class="p">:</span> <span class="p">[</span><span class="mi">0</span> <span class="mi">0</span> <span class="mi">2</span> <span class="o">-</span><span class="mi">72</span><span class="p">]</span>
            <span class="p">:</span>
</code></pre></div></div> <p>Since the transformation object <code class="language-plaintext highlighter-rouge">affine3d</code> has its methods, we can simply use it too:</p> <div class="language-matlab highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;&gt;</span> <span class="n">Info</span><span class="o">.</span><span class="n">Transform</span><span class="o">.</span><span class="n">transformPointsInverse</span><span class="p">([</span><span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span><span class="p">])</span>

<span class="nb">ans</span> <span class="o">=</span>

    <span class="mi">45</span>    <span class="mi">63</span>    <span class="mi">36</span>
</code></pre></div></div> <p>This is the voxel-coordinate of the world-origin!</p> <p>More general 3D computer graphics community uses formats such as VTK (<a href="https://vtk.org">Visualization Toolkit</a>) and ITK (<a href="https://itk.org">Insight Toolkit</a>).</p> <h3 id="3-d-triangle-mesh">3-D triangle mesh</h3> <p>What about 3-D surfaces? A continuous surface is triangulated to represent it as a <strong>triangle mesh</strong>, which is a set of tiny triangles stitched together like this donut:</p> <table> <tbody> <tr> <td><img alt="torus" src="https://upload.wikimedia.org/wikipedia/commons/thumb/a/aa/Torus-triang.png/1635px-Torus-triang.png" width="400px" data-zoomable=""/></td> </tr> <tr> <td><em>Fig 1. A triangulated torus</em> (CC-BY-SA-3.0: <a href="https://commons.wikimedia.org/w/index.php?curid=30856793">Ag2gaeh</a>)</td> </tr> </tbody> </table> <p>To store this donut, we need a bit more tables. First, locations of vertices:</p> <table> <thead> <tr> <th>VertexID</th> <th>World (mm)</th> </tr> </thead> <tbody> <tr> <td>1</td> <td>(-0.5, -3.0, 0.5)</td> </tr> <tr> <td>2</td> <td>(-0.5, -2.5, 0.5)</td> </tr> <tr> <td>:</td> <td>:</td> </tr> <tr> <td>V</td> <td>(3.1, -6.0, -2.0)</td> </tr> </tbody> </table> <p>Second, an ordered list of vertices describing how each face is constructed:</p> <table> <thead> <tr> <th>FaceID</th> <th>VertexIDs</th> </tr> </thead> <tbody> <tr> <td>1</td> <td>(1, 6, 3)</td> </tr> <tr> <td>2</td> <td>(3, 10, 6)</td> </tr> <tr> <td>:</td> <td>:</td> </tr> <tr> <td>F</td> <td>(45, 21, 55)</td> </tr> </tbody> </table> <p>Finally, we want to store a large vector describing a scalar-map over vertices:</p> \[\mathbf{I} \in \mathbb{N}^{V} = [a_1, a_2, \cdots, a_V ]\] <p>How do we save all this information in a binary format consistently across computing languages? Luckily, since 2007, GIfTI (<a href="https://www.nitrc.org/projects/gifti/">geometry format under the NIfTI</a>) has been used as a standard format to read and write triangle mesh and vertex-mapped scalar data. So what‚Äôs the problem? ü§∑</p> <h2 id="inconsistent-triangulations">Inconsistent triangulations</h2> <p>A same structure can be triangulated differently. For example, these two spheres can be rendered very similarly with the interpolation of face colors, but there underlying triangulation and how they were created are quite different (<em>Fig 2</em>). The left one is created by marching cube algorithm, which estimate an isosurface (a 3-D boundary with a constant value) within each cube made of 8 voxels as vertices <a href="https://www.mathworks.com/help/matlab/ref/isosurface.html">[HTML]</a>. The right one is created by dividing faces of an icosahedron (a polyhedron with 20 faces) <a href="https://www.mathworks.com/matlabcentral/fileexchange/50105-icosphere">[HTML]</a>.</p> <table> <tbody> <tr> <td><img alt="spheres" src="/assets/img/blog/surf-fig2.png" width="600px" data-zoomable=""/></td> </tr> <tr> <td><em>Fig 2. Two spheres with VERY different triangulations.</em></td> </tr> </tbody> </table> <ul id="surf1" class="tab" data-tab="07883c90-aec4-413d-9146-0fe709d8118a" data-name="surf1"> <li class="active" id="surf1-matlab"> <a href="#">matlab </a> </li> <li id="surf1-python"> <a href="#">python </a> </li> </ul> <ul class="tab-content" id="07883c90-aec4-413d-9146-0fe709d8118a" data-name="surf1"> <li class="active"> <div class="language-matlab highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">% marching cube:</span>
<span class="n">res</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">;</span>
<span class="n">r</span> <span class="o">=</span> <span class="mi">8</span><span class="p">;</span>
<span class="n">x</span> <span class="o">=</span> <span class="o">-</span><span class="n">r</span><span class="p">:</span><span class="n">res</span><span class="p">:</span><span class="n">r</span><span class="p">;</span>
<span class="n">y</span> <span class="o">=</span> <span class="o">-</span><span class="n">r</span><span class="p">:</span><span class="n">res</span><span class="p">:</span><span class="n">r</span><span class="p">;</span>
<span class="n">z</span> <span class="o">=</span> <span class="o">-</span><span class="n">r</span><span class="p">:</span><span class="n">res</span><span class="p">:</span><span class="n">r</span><span class="p">;</span>
<span class="p">[</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">Z</span><span class="p">]</span> <span class="o">=</span> <span class="nb">meshgrid</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">z</span><span class="p">);</span>
<span class="n">marchingSphere</span> <span class="o">=</span> <span class="nb">isosurface</span><span class="p">(</span><span class="n">x</span> <span class="p">,</span><span class="n">y</span> <span class="p">,</span> <span class="n">z</span><span class="p">,</span> <span class="n">fun</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">Y</span><span class="p">,</span><span class="n">Z</span><span class="p">),</span> <span class="mi">0</span><span class="p">);</span>

<span class="c1">% icosphere:</span>
<span class="n">icoSphere</span> <span class="o">=</span> <span class="nb">struct</span><span class="p">();</span>
<span class="p">[</span><span class="n">icoSphere</span><span class="o">.</span><span class="n">vertices</span><span class="p">,</span> <span class="n">icoSphere</span><span class="o">.</span><span class="n">faces</span><span class="p">]</span> <span class="o">=</span> <span class="n">icosphere</span><span class="p">(</span><span class="mi">3</span><span class="p">);</span>
</code></pre></div></div> </li> <li> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># chatGPT-translated:
</span><span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="n">skimage.measure</span>
<span class="kn">import</span> <span class="n">trimesh</span>

<span class="k">def</span> <span class="nf">fun</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">Z</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">X</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="n">Y</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="n">Z</span><span class="o">**</span><span class="mi">2</span> <span class="o">-</span> <span class="mi">1</span>  <span class="c1"># Example function defining a sphere
</span>
<span class="c1"># Marching Cubes
</span><span class="n">res</span> <span class="o">=</span> <span class="mf">0.1</span>
<span class="n">r</span> <span class="o">=</span> <span class="mi">8</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">arange</span><span class="p">(</span><span class="o">-</span><span class="n">r</span><span class="p">,</span> <span class="n">r</span> <span class="o">+</span> <span class="n">res</span><span class="p">,</span> <span class="n">res</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">arange</span><span class="p">(</span><span class="o">-</span><span class="n">r</span><span class="p">,</span> <span class="n">r</span> <span class="o">+</span> <span class="n">res</span><span class="p">,</span> <span class="n">res</span><span class="p">)</span>
<span class="n">z</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">arange</span><span class="p">(</span><span class="o">-</span><span class="n">r</span><span class="p">,</span> <span class="n">r</span> <span class="o">+</span> <span class="n">res</span><span class="p">,</span> <span class="n">res</span><span class="p">)</span>
<span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">Z</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">meshgrid</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">z</span><span class="p">,</span> <span class="n">indexing</span><span class="o">=</span><span class="sh">'</span><span class="s">ij</span><span class="sh">'</span><span class="p">)</span>
<span class="n">volume</span> <span class="o">=</span> <span class="nf">fun</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">Z</span><span class="p">)</span>
<span class="n">verts</span><span class="p">,</span> <span class="n">faces</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">skimage</span><span class="p">.</span><span class="n">measure</span><span class="p">.</span><span class="nf">marching_cubes</span><span class="p">(</span><span class="n">volume</span><span class="p">,</span> <span class="n">level</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">spacing</span><span class="o">=</span><span class="p">(</span><span class="n">res</span><span class="p">,</span> <span class="n">res</span><span class="p">,</span> <span class="n">res</span><span class="p">))</span>

<span class="c1"># Icosphere
</span><span class="k">def</span> <span class="nf">generate_icosphere</span><span class="p">(</span><span class="n">subdivisions</span><span class="o">=</span><span class="mi">3</span><span class="p">):</span>
    <span class="n">sphere</span> <span class="o">=</span> <span class="n">trimesh</span><span class="p">.</span><span class="n">creation</span><span class="p">.</span><span class="nf">icosphere</span><span class="p">(</span><span class="n">subdivisions</span><span class="o">=</span><span class="n">subdivisions</span><span class="p">)</span>
    <span class="k">return</span> <span class="p">{</span><span class="sh">'</span><span class="s">vertices</span><span class="sh">'</span><span class="p">:</span> <span class="n">sphere</span><span class="p">.</span><span class="n">vertices</span><span class="p">,</span> <span class="sh">'</span><span class="s">faces</span><span class="sh">'</span><span class="p">:</span> <span class="n">sphere</span><span class="p">.</span><span class="n">faces</span><span class="p">}</span>

<span class="n">icoSphere</span> <span class="o">=</span> <span class="nf">generate_icosphere</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
</code></pre></div></div> </li> </ul> <p>Extracting an isosurface from a volume is highly efficient‚Äìeven can be implemented for real-time visualization. But the underlying triangulation can drastically vary across data, making surface-based registration difficult.</p> <h2 id="spherical-registration">Spherical registration</h2> <p>The cortical surface of a hemisphere is often modelled as a closed surface. If you ignore the corpus callosum, thalamus, basal ganglia, and hippocampus, the cerebral cortex can be seen as a sphere with a hole. If we just sagittally cut the corpus callosum and wrap around the medial structures, you now have a closed surface, topologically homologous to a sphere!</p> <p>You may ask:</p> <blockquote> <p>ü§®: ‚ÄúBut why do you want to cut two hemispheres üß† into two icosahedrons? ‚öΩÔ∏è‚öΩÔ∏è‚Äù</p> </blockquote> <p>Why not? ü§ì Wouldn‚Äôt it be so nice if all cortical surfaces have the identical Euler characteristic of $\chi=2$? ü•π Without holes, without intersecting edges or faces, without non-differentiable spikes, just like a perfect just like a perfect sphere!ü§© Also, wouldn‚Äôt it be so nice if all those tiny trianglesüìê are well-orderedüòá (i.e., the vertices are listed in an outward-counter-clock-wise order along the columns in the face list so that the cross-product of v1v2 and v1v3 would be the outward face-normal) and regular in size? ü§ó</p> <p>Besides the true joy, there are practical reasons why a spherical modeling is something to consider.</p> <p>[to be continued‚Ä¶]</p> <h2 id="incompatible-software">Incompatible software</h2> <p>Since late 90s, multiple cortical surface templates have been proposed and used. Let me list a few:</p> <ul> <li> <p>FreeSurfer: <a href="https://surfer.nmr.mgh.harvard.edu/">https://surfer.nmr.mgh.harvard.edu/</a></p> <ul> <li> <p>Connectome Workbench: <a href="https://www.humanconnectome.org/software/get-connectome-workbench">https://www.humanconnectome.org/software/get-connectome-workbench</a></p> </li> <li> <p>OpenNeuro Average: <a href="https://feilong.github.io/tpl-onavg/">https://feilong.github.io/tpl-onavg/</a></p> </li> </ul> </li> <li> <p>Caret: <a href="https://www.nitrc.org/projects/caret/">https://www.nitrc.org/projects/caret/</a></p> </li> <li> <p>Brain Voyager: <a href="https://www.brainvoyager.com/">https://www.brainvoyager.com/</a></p> </li> <li> <p>CIVET: <a href="https://mcin.ca/technology/civet/">https://mcin.ca/technology/civet/</a></p> </li> <li> <p>Brain Visa: <a href="https://brainvisa.info/">https://brainvisa.info/</a></p> </li> <li> <p>CAT12: <a href="https://github.com/ChristianGaser/cat12.git">https://github.com/ChristianGaser/cat12.git</a></p> </li> </ul>]]></content><author><name></name></author><category term="brain"/><category term="nerd"/><summary type="html"><![CDATA[Surface-based analysis that can work very various surfaces]]></summary></entry><entry><title type="html">TeaP2025 ended</title><link href="https://seunggookim.github.io/blog/2025/teap/" rel="alternate" type="text/html" title="TeaP2025 ended"/><published>2025-03-13T00:00:00+00:00</published><updated>2025-03-13T00:00:00+00:00</updated><id>https://seunggookim.github.io/blog/2025/teap</id><content type="html" xml:base="https://seunggookim.github.io/blog/2025/teap/"><![CDATA[<p>TeaP2025 (2025-03-09 to 2025-03-12, Frankfurt am Main, Germany) ended successfully. Here are some thoughts to share:</p> <h2 id="llm-based-conference-organization">LLM-based conference organization</h2> <p>The idea was: ‚ÄúCan we use the large-language model [LLM] embedding to measure semantic distance between conference abstracts?‚Äù ü§î</p> <h3 id="large-language-model">Large-language model?</h3> <p>You know, things like ChatGPT, Claude, Gemini ü§ñ. The things that parse strings of text tokens and generate fake text that sounds plausible. Maybe something similar to our ‚Äúlanguage center‚Äù in our brains does when we are extremely drunken. And also things that generate your fake homework essays and correct typos of this post.</p> <h3 id="embedding">Embedding?</h3> <p>It‚Äôs what non-philosophers think a ‚Äúrepresentation‚Äù would be like for an artificial neural network like a LLM. This is defined for a word, a sentenece, a paragraph, or a whole writing given as a set of 4000+ numbers (i.e., a vector) for an OpenAI model (<code class="language-plaintext highlighter-rouge">text-embedding-3-large</code>). See also: <a href="https://platform.openai.com/docs/api-reference/embeddings/create">https://platform.openai.com/docs/api-reference/embeddings/create</a></p> <h3 id="clustering-and-organizing">Clustering and organizing</h3> <p>Once you define the distance between abstracts, then you can perform clustering on that.</p> <p>We wanted to organize talk sessions while satisfying the following criteria:</p> <ul> <li> <p>Find near-optimal clustering with a maximaum of six abstracts per session.</p> </li> <li> <p>Once clusters are found, maximize distances between parallel sessions.</p> </li> </ul> <p>We wanted to organize poster sessions while considering these conditions:</p> <ul> <li> <p>Find near-optimal clustering while maintaining the number of clusters manageable for manual browsing on the conference web page (k &lt; 10).</p> </li> <li> <p>Ensure that poster presenters to view other posters on similar topics. To this end, the closest three posters are assigned to different days.</p> </li> <li> <p>Optimize attendees‚Äô walking paths by arranging posters so that their semantic similarity aligns with their physical proximity.</p> </li> </ul> <p><b>Want to know more?</b> <a href="/assets/pdf/posters/Kim.2025.emb_teap25_v3.pdf">[PDF]</a></p>]]></content><author><name></name></author><category term="nerd"/><summary type="html"><![CDATA[Helping organizing a conference]]></summary></entry><entry><title type="html">ChatGPT4o for BASH one-liners</title><link href="https://seunggookim.github.io/blog/2024/oneliner/" rel="alternate" type="text/html" title="ChatGPT4o for BASH one-liners"/><published>2024-09-15T00:00:00+00:00</published><updated>2024-09-15T00:00:00+00:00</updated><id>https://seunggookim.github.io/blog/2024/oneliner</id><content type="html" xml:base="https://seunggookim.github.io/blog/2024/oneliner/"><![CDATA[ <p>Apple and OpenAI recently made a deal, and now I can open ChatGPT window with Alt+Space on MacOS but still limited without a paid subscription. But still, it is a lot better than me in writing magical BASH commands, and the source of all evil‚Äìthe regular expression.</p> <p>I wanted to automatically update the list of journals in the <code class="language-plaintext highlighter-rouge">resume.json</code> file for this web page from the directories in my review folder. For this I need to find directories from the folder except for ones starting with <code class="language-plaintext highlighter-rouge">_</code>, select only the last names from the full path, then sort them ignoring cases, then replace a line break with a string of a comma and a space, then replace a place-holder <code class="language-plaintext highlighter-rouge">&lt;ADD_HERE&gt;</code> in a temporary file <code class="language-plaintext highlighter-rouge">resume-addhere.json</code> with this string, then save everything as a new <code class="language-plaintext highlighter-rouge">resume.json</code> after making a backup of the old <code class="language-plaintext highlighter-rouge">resume.json</code> file.</p> <p>So, this all can be done by this magic one-linerü™Ñ:</p> <ul id="script" class="tab" data-tab="12715ee8-b6d2-4822-924e-2153794971bf" data-name="script"> <li class="active" id="script-bash"> <a href="#">bash </a> </li> </ul> <ul class="tab-content" id="12715ee8-b6d2-4822-924e-2153794971bf" data-name="script"> <li class="active"> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">sed</span> <span class="s2">"s/</span><span class="se">\"</span><span class="s2">&lt;ADD_HERE&gt;</span><span class="se">\"</span><span class="s2">: </span><span class="se">\"\"</span><span class="s2">/</span><span class="se">\"</span><span class="s2">summary</span><span class="se">\"</span><span class="s2">: </span><span class="se">\"</span><span class="sb">`</span>find <span class="k">${</span><span class="nv">MY_FOLDER_WHERE_I_PUT_MY_REVIEWS</span><span class="k">}</span> <span class="nt">-depth</span> 1 <span class="nt">-type</span> d <span class="o">!</span> <span class="nt">-name</span> <span class="s1">'_*'</span> | <span class="nb">awk</span> <span class="nt">-F</span>/ <span class="s1">'{print $NF}'</span> | <span class="nb">sort</span> <span class="nt">-f</span> | <span class="nb">sed</span> <span class="nt">-e</span> <span class="s1">':a'</span> <span class="nt">-e</span> <span class="s1">'N'</span> <span class="nt">-e</span> <span class="s1">'$!ba'</span> <span class="nt">-e</span> <span class="s1">'s/\n/, /g'</span><span class="sb">`</span><span class="se">\"</span><span class="s2">/g"</span> resume-addhere.json <span class="o">&gt;</span> resume.json
</code></pre></div></div> </li> </ul> <p>And it <a href="/cv/">worked</a>!:satisfied:</p> <p>(But actually the ChatGPT took me a while since it hallucinated a bit about the sed command and was quite stubborn about it, then came up with a seemingly unnecessarily long option phrase‚Ä¶:see_no_evil:)</p> <p><em>UPDATED on 2024-09-16:</em> I‚Äôve got more stories on this now! This script worked fine on the local computer, but it doesn‚Äôt build and deploy the website on the remoteüôÉ. So I learned more about how to find error messages from the deployment process built in the workflows; and learned that all JSON files in the directory should be valid. So I made the place-holder a valid element:¬†<code class="language-plaintext highlighter-rouge">"&lt;ADD_HERE&gt;": ""</code>. The hard lesson was that I <em>must</em> obey the JSON format, all the time‚Ä¶</p>]]></content><author><name></name></author><category term="code"/><category term="nerd"/><summary type="html"><![CDATA[It's a magic!üò≥]]></summary></entry><entry><title type="html">LEAüëß</title><link href="https://seunggookim.github.io/blog/2024/lea/" rel="alternate" type="text/html" title="LEAüëß"/><published>2024-09-08T00:00:00+00:00</published><updated>2024-09-08T00:00:00+00:00</updated><id>https://seunggookim.github.io/blog/2024/lea</id><content type="html" xml:base="https://seunggookim.github.io/blog/2024/lea/"><![CDATA[ <table> <tbody> <tr> <td><img src="/assets/img/blog/lea-fig1.png" width="500px" alt="fig1" loading="eager" style="float" data-zoomable=""/></td> </tr> <tr> <td><em>Fig 1. LEA‚Äôs default plot.</em></td> </tr> </tbody> </table> <p>I‚Äôve created a MATLAB package called <a href="https://github.com/seunggookim/lea">LEAüëß</a> , which stands for Linearized Encoding Analysis. This was developed for my tutorial lecture at <a href="https://github.com/seunggookim/ksmpc-ss24-sess3">KSMPC-SS24</a>.</p> <p>While its functionality is limited, still one can use for most of behavioural and physiological time series data. Let me know if you‚Äôre interested in using this for your research. I am willing to further develop this for collaboration.</p>]]></content><author><name></name></author><category term="code"/><summary type="html"><![CDATA[Linearized Encoding Analysis MATLAB package]]></summary></entry><entry><title type="html">How do I edit a file in a Terminal? ü§∑</title><link href="https://seunggookim.github.io/blog/2024/clied/" rel="alternate" type="text/html" title="How do I edit a file in a Terminal? ü§∑"/><published>2024-08-21T00:00:00+00:00</published><updated>2024-08-21T00:00:00+00:00</updated><id>https://seunggookim.github.io/blog/2024/clied</id><content type="html" xml:base="https://seunggookim.github.io/blog/2024/clied/"><![CDATA[<p><img src="/assets/img/blog/clied-fig1.png" width="600px"/></p> <p>This is a light-hearted tutorial on <s>the holy Editor War</s> how to use a command-line interface (CLI) editors for beginners (who are unfamiliar with the Terminal), entitled ‚ÄúHow do I edit a file in a Terminal? ü§∑‚Äù, presented on the 21st of August, 2024 at MPIEA, Frankfurt am Main <a href="https://raw.githubusercontent.com/seunggookim/clied/8ecedbdd40e95e0340f1607bd578ea54fbc978d5/docs/2024-08-21_LabmeetingNCML_cli_Kim.pdf">[slides]</a> <a href="https://github.com/seunggookim/clied">[repo]</a></p> <p><em>UPDATE:</em> This is a part of <a href="/teaching/teach_mpi_computers/">a series of tutorials</a>.</p>]]></content><author><name></name></author><category term="nerd"/><summary type="html"><![CDATA['You cannot make a spoon that is better than a spoon' -Umbert Eco]]></summary></entry><entry><title type="html">Time deconvolution</title><link href="https://seunggookim.github.io/blog/2024/deconv/" rel="alternate" type="text/html" title="Time deconvolution"/><published>2024-08-20T00:00:00+00:00</published><updated>2024-08-20T00:00:00+00:00</updated><id>https://seunggookim.github.io/blog/2024/deconv</id><content type="html" xml:base="https://seunggookim.github.io/blog/2024/deconv/"><![CDATA[<p>Let us consider a linear model: \begin{equation} \label{eq:fir} \mathbf{y} = \mathbf{X} \mathbf{b} + \mathbf{e} \end{equation} where \(\mathbf{y} \in \Re^{T\,\times\,1}\) is a response time series over \(T\) timepoints, \(\mathbf{X} \in \Re^{T\,\times\,P}\) is a design matrix of \(P\) predictors such that \(\|\mathbf{X}'\mathbf{X}\| &gt; 0\), \(\mathbf{b} \in \Re^{P\,\times\,1}\) is an unknown weight vector, \(\mathbf{e} \in \Re^{T\,\times\,1}\) is a Gaussian noise vector \(\mathbf{e} \sim \mathcal{N} (\mathbf{0}, \sigma^2\mathbf{I})\).</p> <p>When the \(\mathbf{X}\) is a finite impulse respnose (FIR) design matrix (e.g., Toeplitz matrix), the linear model describes a convolution between one column in \(\mathbf{X}\) (e.g., \(\mathbf{x}^{(1)}\) where \(\)) and the vector \(\mathbf{b}\). Then, solving this model to find \(\mathbf{b}\) is equivalent to finding a deconvoultion from \(\mathbf{y}\) with \(\mathbf{X}\) to recover \(\mathbf{b}\).</p> <p>For that an FIR model is prone to overfitting to noise due to its flexibility, the stability of solution can be earned by introducing a small bias such as \(l^2\) penalty: \begin{equation} \mathbf{ {\hat b} } = (\mathbf{X}‚Äô \mathbf{X} + \lambda \mathbf{I})^{-1} \mathbf{y} \end{equation} which is a well-known problem.</p> <p>In fMRI terminologies, \(\mathbf{b}\) is the HRF kernel for a given design vector \(\mathbf{x}^{(1)}\), which is assumed to be identical to underlying neural activity. Thus, without knowing the <em>true HRF</em>, estimating the <em>true neural activity</em> (\(\mathbf{x}^{(1)}\)) from \(\mathbf{y}\) is met with underdeterminedness. :shrug:</p>]]></content><author><name></name></author><category term="math"/><category term="fmri"/><summary type="html"><![CDATA[Is it a sample thing?]]></summary></entry><entry><title type="html">Temporal orders</title><link href="https://seunggookim.github.io/blog/2024/orders/" rel="alternate" type="text/html" title="Temporal orders"/><published>2024-08-20T00:00:00+00:00</published><updated>2024-08-20T00:00:00+00:00</updated><id>https://seunggookim.github.io/blog/2024/orders</id><content type="html" xml:base="https://seunggookim.github.io/blog/2024/orders/"><![CDATA[<p>Because of the sluggish (4-6 secs to peak) :snail: nature of BOLD (blood-oxygen-level-dependent) fMRI signal, the temporal orders of music, neural processing, and behavioral outcomes can be difficult to model. :see_no_evil:</p> <p>Consider a hypothetical case:</p> <table> <tbody> <tr> <td><img src="/assets/img/blog/orders-fig1.png" width="600px" alt="fig1" loading="eager" style="float" data-zoomable=""/></td> </tr> <tr> <td><em>Figure 1. A hypothetical case of temporal orders. MUSIC represents an impulse-like feature that evokes emotional response. NEURON shows a follow-up neuronal activity from 0.1 sec. BOLD signal is delayed by ~6 sec from the neural activity. BEHAVIOR-RED indicates a rapid response within 1-2 sec. BEHAVIOR-CYAN indicates a slow response even 8 seconds after the event.</em></td> </tr> </tbody> </table> <p><br/> We often assume an linear Granger causality from <code class="language-plaintext highlighter-rouge">MUSIC ‚Üí NEURON ‚Üí BEHAVIOR</code>. This may be too simplistic to model all kinds of responses, but it should do some of them.</p> <p>However, because the BOLD signal is a smoothed and delayed neural activity due to the slow heamodynamics (neural/glial activity uses up oxygen in the blood ‚Üí (perhaps) astrocytes control the blood vessel tension ‚Üí an influx of oxygenated blood), this linear Granger causaility can be broken: <code class="language-plaintext highlighter-rouge">MUSIC ‚Üí BEHAVIOR ‚Üí BOLD</code>. :confounded:</p> <p>Moreover, if a certain musical event is mediated by a neurochemical modulation, the affective response may take even longer than BOLD (i.e., BEHAVIOR-CYAN; or is this unrealistic?)</p> <p>In this case, using negative lags can be a solution? :shrug:</p> <hr/> <p><em>August 25, 2024</em></p> <p>But how do we know if the BEHAVIOR-CYAN is actually from this MUSIC event if this is via something that we don‚Äôt have data to model?</p> <p>Let us say in via some mysterious neurochemical mechanism, there exist a different neuron that is involved in this slow response:</p> <table> <tbody> <tr> <td><img src="/assets/img/blog/orders-fig2.png" width="700px" alt="fig1" loading="eager" style="float" data-zoomable=""/></td> </tr> <tr> <td><em>Figure 2. A hypothetical case of temporal orders with some more stuff. Perhaps for BEHAVIOR-CYAN, NEURON-PURPLE activity should be there and BOLD-ORANGE response can be seen.</em></td> </tr> </tbody> </table> <p><br/> Even without the BOLD delay, now we are discussing some magical process like this:magic_wand::</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>MUSIC ‚Üí NEURON1 ‚Üí BEHAVIOR1 ‚Üí (SOME MAGIC) ‚Üí NEURON2 ‚Üí BEHAVIOR2 
</code></pre></div></div> <p>But then, this cannot be shown in BOLD-GREEN but only in BOLD-ORANGE. :thinking:</p>]]></content><author><name></name></author><category term="fmri"/><category term="stat"/><summary type="html"><![CDATA[Twisted Granger causality]]></summary></entry><entry><title type="html">Projection matrix</title><link href="https://seunggookim.github.io/blog/2024/regproj/" rel="alternate" type="text/html" title="Projection matrix"/><published>2024-04-26T00:00:00+00:00</published><updated>2024-04-26T00:00:00+00:00</updated><id>https://seunggookim.github.io/blog/2024/regproj</id><content type="html" xml:base="https://seunggookim.github.io/blog/2024/regproj/"><![CDATA[<p>Let us consider a linear model: \begin{equation} \label{eq:fir} \mathbf{y} = \mathbf{X} \mathbf{b} + \mathbf{e} \end{equation} where \(\mathbf{y} \in \Re^{T\,\times\,1}\) is a response vector over \(T\) timepoints, \(\mathbf{X} \in \Re^{T\,\times\,P}\) is a design matrix of \(P\) predictors such that \(\|\mathbf{X}'\mathbf{X}\| &gt; 0\), \(\mathbf{b} \in \Re^{P\,\times\,1}\) is an unknown weight vector, \(\mathbf{e} \in \Re^{T\,\times\,1}\) is a Gaussian noise vector \(\mathbf{e} \sim \mathcal{N} (\mathbf{0}, \sigma^2\mathbf{I}_{T})\) where \(\sigma^2\) is a variance scalar and \(\mathbf{I}_T \in \Re^{T\,\times\,T}\) is an identity matrix.</p> <p>In a ridge regression and cross-validation over multiple partitions of data, if we use Pearson correlation for a prediction performance measure, the expectation of it can be simplified:</p> <p>\begin{equation} \label{eq:expcorr1} \mathbb{E}\left[\text{corr} \left( \hat{\mathbf y}_{2},\, \mathbf y_2 \right) \right] \propto \mathbf{s}_1‚Äô \mathbf{P}‚Äô \mathbf{s}_2 \end{equation}</p> <p>where \(\mathbf{s}\_i = \mathbf{X}\_i \mathbf{b}\) is a true signal in the \(i\)-th partition, and the first partition is <code class="language-plaintext highlighter-rouge">training</code> set and the second partition is <code class="language-plaintext highlighter-rouge">testing</code> set.</p> <p>The ridge projection matrix \(\mathbf P = \mathbf{X}_2 \mathbf{X}_1^{+} + \lambda \mathbf{I}\) can be somewhere between these two extreme cases depending on the optimal \(\lambda\):</p> \[\begin{cases} \mathbf{P} \approx \lambda \mathbf{I} &amp; \text{if } \lambda \gg \|\mathbf{X}_2 \mathbf{X}_1^{+}\| \\ \mathbf{P} = \mathbf{X}_2 \mathbf{X}_1^{+} &amp; \text{if } \lambda = 0 \end{cases}\] <p>where \((\cdot)^+\) denotes Moore‚ÄìPenrose inverse.</p> <p>Now, it shows for a higher regularization (i.e., a smaller signal), the projection matrix gets similar to an identity matrix, making the prediction accuracy highly dependent on the product of two true signals (\(\mathbf{s}_1'\mathbf{s}_2\)). :thinking: And this should be zero in a usual case.</p>]]></content><author><name></name></author><category term="math"/><category term="stat"/><summary type="html"><![CDATA[A little bit of mumbling]]></summary></entry></feed>