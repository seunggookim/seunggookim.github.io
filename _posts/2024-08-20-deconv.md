---
layout: post
title: Time deconvolution
date: 2024-08-20
description: Is it a sample thing?
tags: math fmri
categories:
thumbnail:
giscus_comments: true
---

Let us consider a linear model:
\begin{equation}
\label{eq:fir}
\mathbf{y} = \mathbf{X} \mathbf{b} + \mathbf{e}
\end{equation}
where
$$\mathbf{y} \in \Re^{T\,\times\,1}$$ is a response time series over $$T$$ timepoints,
$$\mathbf{X} \in \Re^{T\,\times\,P}$$ is a design matrix of $$P$$ predictors such that $$\|\mathbf{X}'\mathbf{X}\| > 0$$,
$$\mathbf{b} \in \Re^{P\,\times\,1}$$ is an unknown weight vector,
$$\mathbf{e} \in \Re^{T\,\times\,1}$$ is a Gaussian noise vector
$$\mathbf{e} \sim \mathcal{N} (\mathbf{0}, \sigma^2\mathbf{I})$$.

When the $$\mathbf{X}$$ is a finite impulse respnose (FIR) design matrix (e.g., Toeplitz matrix),
the linear model describes a convolution between one column in $$\mathbf{X}$$ (e.g., $$\mathbf{x}^{(1)}$$ where $$ $$) and the vector $$\mathbf{b}$$.
Then, solving this model to find $$\mathbf{b}$$ is equivalent to finding a deconvoultion from $$\mathbf{y}$$ with $$\mathbf{X}$$ to recover $$\mathbf{b}$$.

For that an FIR model is prone to overfitting to noise due to its flexibility,
the stability of solution can be earned by introducing a small bias such as $$l^2$$ penalty:
\begin{equation}
\mathbf{ {\hat b} } = (\mathbf{X}' \mathbf{X} + \lambda \mathbf{I})^{-1} \mathbf{y}
\end{equation}
which is a well-known problem.

In fMRI terminologies, $$\mathbf{b}$$ is the HRF kernel for a given design vector $$\mathbf{x}^{(1)}$$, which is assumed to be identical to underlying neural activity.
Thus, without knowing the _true HRF_, estimating the _true neural activity_ ($$\mathbf{x}^{(1)}$$) from $$\mathbf{y}$$ is met with underdeterminedness. :shrug:
