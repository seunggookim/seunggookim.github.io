---
layout: page
title: Surfing LEA üèÑ‚Äç‚ôÄÔ∏èüëß
description: Surface-based analysis that can work very various surfaces
importance: 2
tags: brain nerd
giscus_comments: true
related_publication: true
---

First, surface-based analysis is cool because the cerebral cortex üß† looks like a 2-D Riemannian (differentiable) manifold, of which functional organization seems to be governed by geodesic proximity rather than Euclidean proximity at a mesoscale (a few centimeters or less). 
So, a surface-based analysis is attractive, also for linearized encoding analysis! üëß‚ù§Ô∏èüèÑ‚Äç‚ôÄÔ∏è

However, there are some things that make surface-based analysis more difficult than volume-based analysis.

## Prerequisites
Which information do we need to define a surface? And which information do we need to define a volume?

### Volume
A digital 3-D image (i.e., a volume) is a tensor (or an 3-D array). 
For example, say we have a 3-D image with 2 rows, 3 columns, and 2 pages like:

$$
\mathbf{I} \in \mathbb{N}^{2 \times 3 \times 2} = 
\left[
\begin{array}{c}
\begin{bmatrix}
a & b & c \\
d & e & f
\end{bmatrix}, 
\begin{bmatrix}
g & h & i \\
j & k & l
\end{bmatrix}
\end{array}
\right]
$$

This image itself does not have any location information in it, but we organize them so that it preserves relative spatial information. 
That is, the value $b$ itself doesn't say anything about its location $(1,2,1)$ but we know that $b$ is one column after $a$ and one page before $h$ from the arrangement of the 3-D array.
Such relative information may be sufficient in many applications.
But in neuroimaging, and medical imaging in general, it is very important to precisely know how the voxel $(1,2,1)$ corresponds to a real-world coordinate (i.e., is it $(1, 2, 1) \mathrm{mm}$ or $(10,-200,0.1) \mathrm{cm}$?). And this is defined by the orders and directions of axes, as well as the sampling spacing (or voxel dimensions). 

Why should we consider different orientations of axes?
Because we are looking at a matrix as shown above, we may think it would be **natural** to map LEFT-to-RIGHT along the columns and UP-to-DOWN along the rows (i.e., "Down" for the first dimension; "Right" for the second dimension; can be written as "DR").
However, if we think about a Cartesian plane, we may think that the first coordinate (row) should increase along the LEFT-to-RIGHT direction an the second coordinate (column) should increase along the DOWN-to-UP direction (i.e., "RU")
There are different conventions for the orientations of axes, and all conventions are valid. 
Often, these are written as a three-character string, representing a direction that increases a coordinate of each dimension in Left, Right, Anterior, Posterior, Superior, Inferior. For example, LAS in radiology; RAS in neurology; RSA or RSP in 3D computer graphics.
Of course, are we talking about the viewer's left or the subject's left? It all makes sense in one way.

One simple yet inefficient way to solve this is to save a list of coordinates together with the value map like:

| Voxel     | World (mm)      |
|-----------|-----------------|
| (1, 1, 1) | (-0.5, -3, 0.5) |
| (1, 2, 1) | (-0.5, -2, 0.5) |
| :         | :               |

This list will grow as we have more voxels. A conventional anatomical image contains 4M+ voxels and a functional image has 300K+ voxels. Moreover, this pair of coordinates can be even larger than the scalar value we need to save. Not a very good ideaüòï.

A lot more elegant and efficient way is to save a transformation matrix (4-by-4 matrix with 4 elements are always the same) with the scalar map and calculate the world coordinate of a certain voxel on the fly when asked.
This is a lot easier to do because the transformation of a voxel-based coordinate to a world-based coordinate is a very simple ([4x4] x [4x1]) matrix multiplication.

So, for a volume data, we need to know the voxel-to-world transformation matrix. 
In neuroimaging community, a standard format called NIfTI ([Neuroimaging Informatics Technology Initiative](https://nifti.nimh.nih.gov/)) has been used since 2004.
More general 3D computer graphics community uses formats such as VTK ([Visualization Toolkit](https://vtk.org)) and ITK ([Insight Toolkit](https://itk.org)).

### 3-D triangle mesh
What about 3-D surfaces? A continuous surface is triangulated to represent it as a **triangle mesh**, which is a set of tiny triangles stitched together like this donut:

| <img alt="torus" src="https://upload.wikimedia.org/wikipedia/commons/thumb/a/aa/Torus-triang.png/1635px-Torus-triang.png" width="400px" data-zoomable> |
| _Fig 1. A triangulated torus_ (CC-BY-SA-3.0: [Ag2gaeh](https://commons.wikimedia.org/w/index.php?curid=30856793)) |

To store this donut, we need a bit more tables. First, locations of vertices:

| VertexID  | World (mm)        |
|-----------|-------------------|
| 1         | (-0.5, -3.0, 0.5) |
| 2         | (-0.5, -2.5, 0.5) |
| :         | :                 |
| V         | (3.1, -6.0, -2.0) |


Second, an ordered list of vertices describing how each face is constructed:

| FaceID   | VertexIDs    |
|----------|--------------|
| 1        | (1, 6, 3)    |
| 2        | (3, 10, 6)   |
| :        | :            |
| F        | (45, 21, 55) |


Finally, we want to store a large vector describing a scalar-map over vertices:

$$
\mathbf{I} \in \mathbb{N}^{V} = [a_1, a_2, \cdots, a_V ]
$$

How do we save all this information in a binary format consistently across computing languages? Luckily, since 2007, GIfTI ([geometry format under the NIfTI](https://www.nitrc.org/projects/gifti/)) has been used as a standard format to read and write triangle mesh and vertex-mapped scalar data.
So what's the problem? ü§∑

## Inconsistent triangulations 
A same structure can be triangulated differently. For example, these two spheres look very similar, but there underlying triangulation and how they were created are quite different (_Fig 2_). 
The left one is created by marching cube algorithm, which estimate an isosurface voxel for each voxel where neighboring voxels cross a predetermined boundary [[HTML](https://www.mathworks.com/help/matlab/ref/isosurface.html)].
The right one is created by dividing faces of an icosahedron (a polyhedron with 20 faces) [[HTML](https://www.mathworks.com/matlabcentral/fileexchange/50105-icosphere)].

| <img alt="spheres" src="/assets/img/blog/surf-fig2.png" width="600px" data-zoomable> |
| _Fig 2. Two spheres with VERY different triangulations._ | 

{% tabs script2 %}
{% tab script2 matlab %}
```matlab
% marching cube:
res = 0.1;
r = 8;
x = -r:res:r;
y = -r:res:r;
z = -r:res:r;
[X, Y, Z] = meshgrid(x, y, z);
marchingSphere = isosurface(x ,y , z, fun(X,Y,Z), 0);

% icosphere:
icoSphere = struct();
[icoSphere.vertices, icoSphere.faces] = icosphere(3);
```
{% endtab %}
{% endtabs %}

## Incompatible software

Since late 90s, multiple cortical surface templates have been proposed and used. Let me list a few:

- FreeSurfer: <https://surfer.nmr.mgh.harvard.edu/> 

  - Connectome Workbench: <https://www.humanconnectome.org/software/get-connectome-workbench> 

  - OpenNeuro Average: <https://feilong.github.io/tpl-onavg/>

- Caret: <https://www.nitrc.org/projects/caret/>

- Brain Voyager: <https://www.brainvoyager.com/>

- CIVET: <https://mcin.ca/technology/civet/>

- Brain Visa: <https://brainvisa.info/>

- CAT12: <https://github.com/ChristianGaser/cat12.git>

